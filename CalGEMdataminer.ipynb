{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import time\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "DB_HOST   = config['host']\n",
    "DB_PORT   = config['port']\n",
    "DB_USER   = config['user']\n",
    "DB_PASSWD = config['password']\n",
    "DB_NAME   = config['database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://calgem-pid.conservation.ca.gov/pid/2024CaliforniaOilAndGasWells.csv\n",
    "\n",
    "# Define the years we plan to download from CalGEM\n",
    "years = ['2024']\n",
    "\n",
    "# Iterate over each year we plan to download.\n",
    "for year in years:\n",
    "    print(f'Requesting data for year: {year}')\n",
    "\n",
    "    # Create a dictionary of filenames for each dataset we plan to work with.\n",
    "    calgem_filenames = {\n",
    "        \"wells_file\": f\"{year}CaliforniaOilAndGasWells.csv\"\n",
    "    }\n",
    "\n",
    "    # Construct the CalGEM urls needed to download the datasets.\n",
    "    wells_url = f\"https://calgem-pid.conservation.ca.gov/pid/{calgem_filenames['wells_file']}\"\n",
    "\n",
    "    # step to be able to webscrape the data: https://stackoverflow.com/questions/55711159/pandas-read-csv-from-url-and-include-request-header\n",
    "    # Custom way to tell CalGEM to accept our request for the data.\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11'\n",
    "    }\n",
    "\n",
    "     # Create a dataframe for each dataset from CalGEM, and formats the data as CSV.\n",
    "    df_wells_data = pd.read_csv(wells_url, storage_options=headers)\n",
    "\n",
    "     # add column Year to df_wells_data in each year downloaded.\n",
    "    df_wells_data['ReportYear'] = year\n",
    "    \n",
    "    # Writes the downloaded CalGEM data to the CSV file.\n",
    "    df_wells_data.to_csv(calgem_filenames['wells_file'])\n",
    "\n",
    "     # Create a connection to the sqlite database.\n",
    "    disk_engine = create_engine(f'mysql://{DB_USER}:{DB_PASSWD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "     # Write the data from each dataset into the corresponding database table.\n",
    "    df_wells_data.to_sql('wells_data', disk_engine, if_exists='replace')\n",
    "\n",
    "print(f\"Completed Downloading of years: {\",\".join([year for year in years])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opendata.arcgis.com/api/v3/datasets/2174fff844e9425ba07acac5cb975b2d_0/downloads/data?format=csv&spatialRefId=4326&where=1%3D1\n",
    "\n",
    "aquifer_exemptions_url = 'https://opendata.arcgis.com/api/v3/datasets/2174fff844e9425ba07acac5cb975b2d_0/downloads/data?format=csv&spatialRefId=4326&where=1%3D1'\n",
    "\n",
    "# string variable\n",
    "project_name = 'aquifer_exemptions'\n",
    "\n",
    "# Create a string for the csv file name.\n",
    "calgem_aquifer_exemption_file = f'{project_name}.csv'\n",
    "\n",
    "# Create a dataframe for each dataset from CalGEM, and formats the data as CSV.\n",
    "df_aquifer_exemptions = pd.read_csv(aquifer_exemptions_url)\n",
    "\n",
    "# Add a 30-second delay\n",
    "time.sleep(15)\n",
    "   \n",
    "# Writes the downloaded CalGEM data to the CSV file.\n",
    "df_aquifer_exemptions.to_csv(calgem_aquifer_exemption_file)\n",
    "\n",
    "# Create a connection to the sqlite database.\n",
    "disk_engine = create_engine(f'mysql://{DB_USER}:{DB_PASSWD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# Write the data from each dataset into the corresponding database table.\n",
    "df_aquifer_exemptions.to_sql(project_name, disk_engine, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://opendata.arcgis.com/api/v3/datasets/62a8c86c840c4fea80664276682cc612_3/downloads?spatialRefId=4326&formats=csv&where=1%3D1\n",
    "\n",
    "facility_boundaries_url = 'https://opendata.arcgis.com/api/v3/datasets/62a8c86c840c4fea80664276682cc612_3/downloads/data?format=csv&spatialRefId=4326&where=1%3D1'\n",
    "\n",
    "# string variable\n",
    "project_name = 'facility_boundaries'\n",
    "\n",
    "# Create a string for the csv file name.\n",
    "calgem_facility_boundaries_file = f'{project_name}.csv'\n",
    "\n",
    "# Create a dataframe for each dataset from CalGEM, and formats the data as CSV.\n",
    "df_facility_boundaries = pd.read_csv(facility_boundaries_url)\n",
    "\n",
    "# Add a 30-second delay\n",
    "time.sleep(15)\n",
    "   \n",
    "# Writes the downloaded CalGEM data to the CSV file.\n",
    "df_facility_boundaries.to_csv(calgem_facility_boundaries_file)\n",
    "\n",
    "# Create a connection to the sqlite database.\n",
    "disk_engine = create_engine(f'mysql://{DB_USER}:{DB_PASSWD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# Write the data from each dataset into the corresponding database table.\n",
    "df_facility_boundaries.to_sql(project_name, disk_engine, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opendata.arcgis.com/api/v3/datasets/a23f5eb6c9cf48a9ad34378a75411bf3_0/downloads/data?format=csv&spatialRefId=4326&where=1%3D1\n",
    "\n",
    "facility_tanks_url = 'https://opendata.arcgis.com/api/v3/datasets/a23f5eb6c9cf48a9ad34378a75411bf3_0/downloads/data?format=csv&spatialRefId=4326&where=1%3D1'\n",
    "\n",
    "# string variable\n",
    "project_name = 'facility_tanks'\n",
    "\n",
    "# Create a string for the csv file name.\n",
    "calgem_facility_tanks_file = f'{project_name}.csv'\n",
    "\n",
    "# Create a dataframe for each dataset from CalGEM, and formats the data as CSV.\n",
    "df_facility_tanks = pd.read_csv(facility_tanks_url)\n",
    "\n",
    "# Add a 30-second delay\n",
    "time.sleep(15)\n",
    "   \n",
    "# Writes the downloaded CalGEM data to the CSV file.\n",
    "df_facility_tanks.to_csv(calgem_facility_tanks_file)\n",
    "\n",
    "# Create a connection to the sqlite database.\n",
    "disk_engine = create_engine(f'mysql://{DB_USER}:{DB_PASSWD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# Write the data from each dataset into the corresponding database table.\n",
    "df_facility_tanks.to_sql(project_name, disk_engine, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opendata.arcgis.com/api/v3/datasets/091104d846af4a6881ab5ff03d516fee_0/downloads/data?format=csv&spatialRefId=4326&where=1%3D1\n",
    "\n",
    "facility_tank_settings_url = 'https://opendata.arcgis.com/api/v3/datasets/091104d846af4a6881ab5ff03d516fee_0/downloads/data?format=csv&spatialRefId=4326&where=1%3D1'\n",
    "\n",
    "# string variable\n",
    "project_name = 'district_boundaries'\n",
    "\n",
    "# Create a string for the csv file name.\n",
    "calgem_facility_tank_settings_file = f'{project_name}.csv'\n",
    "\n",
    "# Create a dataframe for each dataset from CalGEM, and formats the data as CSV.\n",
    "df_facility_tank_settings = pd.read_csv(facility_tank_settings_url)\n",
    "\n",
    "# Add a 30-second delay\n",
    "time.sleep(15)\n",
    "\n",
    "# Writes the downloaded CalGEM data to the CSV file.\n",
    "df_facility_tank_settings.to_csv(calgem_facility_tank_settings_file)\n",
    "\n",
    "# Create a connection to the sqlite database.\n",
    "disk_engine = create_engine(f'mysql://{DB_USER}:{DB_PASSWD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# Write the data from each dataset into the corresponding database table.\n",
    "df_facility_tank_settings.to_sql(project_name, disk_engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
